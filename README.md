# Foundation Models for Optimization and Reasoning

- Zikang Yu, Jinbiao Chen, Jiahai Wang*, Combination-of-expert with knowledge sharing for cross-task vehicle routing problems, ICLR 2026.

- Zhaoyang Wang, Shaohan Huang, Yuxuan Liu, Jiahai Wang*, et al., Democratizing reasoning ability: Tailored learning from large language model, EMNLP 2023.

- Jianpeng Zhou, Wanjun Zhong, Yanlin Wang, Jiahai Wang*, Adaptive-solver framework for dynamic strategy selection in large language model reasoning, Information Processing and Management, vol.62, no.3, 104052, May 2025.

- Chenhui Liu, Jianpeng Zhou, Jiahai Wang*, Chain-of-relations: Faithful and efficient LLM reasoning over knowledge graphs via relation-centric exploration, ACL 2026.

- Jianpeng Zhou, Qisheng Hu, Jiahai Wang*, Wenya Wang*, Policy-guided step-wise action planning for controllable reasoning, ACL 2026.



### References
- OPTFM: A scalable multi-view graph transformer for hierarchical pre-training in combinatorial optimization, NeurIPS 2025.

- A systematic survey on large language models for algorithm design, ACM Computing Surveys, 2026.

- Reasoning in a combinatorial and constrained world: Benchmarking LLMs on natural-language combinatorial optimization, 2026.

- A survey of reasoning with foundation models: Concepts, methodilogies, and outlook, ACM Computing Surveys, 2025.

- HYPER: A foundation model for inductive link prediction with knowledge hypergraphs, ICLR 2026.

- G-Reasoner: Foundation models for unified reasoning over graph-structured knowledge, ICLR 2026.

- Graph foundation models: A comprehensive survey, 2025. (https://github.com/Zehong-Wang/Awesome-Foundation-Models-on-Graphs)

